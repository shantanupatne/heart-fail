{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeartFailClassifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO4l62Cas5d7MySUoxAZP9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shantanupatne/heart-fail/blob/master/HeartFailClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJupor1csg3u",
        "colab_type": "text"
      },
      "source": [
        "#Heart Failure Detector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghfgb7cbgpCe",
        "colab_type": "text"
      },
      "source": [
        "Detecting the possibility of heart failure in a patient.\n",
        "Dataset obtained from the UCI Machine Learning Repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ6WxMzNs_rX",
        "colab_type": "text"
      },
      "source": [
        "##Importing Libraries and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AN0nV6RsafZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset = pd.read_csv(r'/content/heart_failure_clinical_records_dataset.csv')\n",
        "X = dataset.iloc[:, 1:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vflrAh9OtEUC",
        "colab_type": "text"
      },
      "source": [
        "##Dataset Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtC0wp_xthOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpEywk0QtM8a",
        "colab_type": "text"
      },
      "source": [
        "##RANFOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaoXxUc9UMJy",
        "colab_type": "text"
      },
      "source": [
        "###Parameters to be tuned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWlwQOATS291",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOaR6bzYURF_",
        "colab_type": "text"
      },
      "source": [
        "###Using RandomizedSearch to tune parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmPKJ7JDtORH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "5b9bedb0-42fc-4118-8501-49dad7df3df1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier(n_estimators = 1000, criterion='entropy', random_state = 1)\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   32.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='entropy',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=1000,\n",
              "                                                    n_...\n",
              "                                                    random_state=1, verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                      70, 80, 90, 100, 110,\n",
              "                                                      None],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [100, 200, 300, 400,\n",
              "                                                         500, 600, 700, 800,\n",
              "                                                         900, 1000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srKnYo0Gfybn",
        "colab_type": "text"
      },
      "source": [
        "###Classification Report and Area Under ROC Curve "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmeXUmWz__tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0194f174-f330-4529-c24b-aa73d15f17ec"
      },
      "source": [
        "y_pred_r = rf_random.predict(X_test)\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "print(classification_report(y_test, y_pred_r))\n",
        "print(roc_auc_score(y_test, y_pred_r, average = 'weighted'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95        46\n",
            "           1       0.85      0.79      0.81        14\n",
            "\n",
            "    accuracy                           0.92        60\n",
            "   macro avg       0.89      0.87      0.88        60\n",
            "weighted avg       0.92      0.92      0.92        60\n",
            "\n",
            "0.8711180124223602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R79YCwNUghgN",
        "colab_type": "text"
      },
      "source": [
        "###Confusion Matrix and Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt8-YKXCtrGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2908d877-180c-4ea6-b087-b3ef376fca36"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred_r))\n",
        "accuracy_score(y_test, y_pred_r)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[44  2]\n",
            " [ 3 11]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}